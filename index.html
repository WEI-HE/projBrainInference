<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Project inference : Design an experiment which requires human subjects to do inference, analyse, mine and model their brain activity to understand how the brain do inference ?">
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">
    <!--load font families-->
    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">
    <link rel="stylesheet" href="fonts/Serif/cmun-serif.css" />
  </head>

  <body>
       <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/steevelaquitaine/projBrainInference">View on GitHub</a>
          <a id="project_author"> Steeve laquitaine </a>
        </header>
    </div>

    <!--TITLE-->
    <div id="proj_title_wrap" class="outer">
        <section id="proj_title" class="inner">
        <h1 id="proj_title"> How does the brain do visual inference ? </h1>
    </div>

    <!--Table of contents-->
    <div id="Table_of_content_wrap" class="outer">
      <section id="table_of_content" class="inner">
        <h3> Table of Content </h3>
        <a href="#Inference"> Inference <br>
        <a href="#Design-an-inference-experiment"> Design an inference experiment <br>
        <a href="#Mapping-brain-areas"> Mapping brain areas <br>
        <a href="#Look-at-fMRI-voxel-responses"> Look at fmri voxel responses  <br>
        <a href="#Decode-stimulus-features-from-brain-activity"> Decode stimulus features from brain activity <br>
        <a href="#Classification-with-a-Machine-learning-algorithm"> &nbsp &nbsp Classification with a Machine learning algorithm <br>
        <a href="#Analysis-of-population-of-voxel-selectivity"> &nbsp &nbsp Analysis of population of voxel selectivity <br>
    </div>
    
    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        
      <h3><a id="Inference" class="anchor" href="#Inference" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Inference</h3>  
      <p></p>

      <h3><a id="Design-an-inference-experiment" class="anchor" href="#Design-an-inference-experiment" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Designing an inference experiment</h3>
      <p>We designed a motion direction estimation experiment in which humans were asked to estimate the motion direction of noisy stimuli on a computer screen. In this experiment statistical optimality can be achieved by combining noisy evidence of the motion with knowledge of the motion direction statistics learnt over motion stimulus history using Bayesian inference</p>
      <center><img src="images/experiment.png"></center>
      
      <h3><a id="Mapping-brain-areas" class="anchor" href="#Mapping-brain-areas" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Mapping brain areas</h3>
      <p> The predominant view is that the brain is a collection of areas that are specialized for particular processing. e.g., The occipital cortex (largely involved in visual perception) has been divided into areas included V1, specialized in edge orientation processing, MT, specialized in motion processing etc...
      The first step consists in mapping those visual areas. We first run an event-related analysis to reveal the brain areas that responded to motion (highlighted below in hot colors (yellow) on different views of an inflated brain </p>
      <center><img src="images/MotionBrain.png" style="width: 50%; height: 50%"/></center>
      
      <h3><a id="Look-at-fMRI-voxel-responses" class="anchor" href="#Look-at-fMRI-voxel-responses" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Look at fMRI voxel responses</h3>
          
      <!--code-->
      <section class="code">    
        <p>  >> slfmriInitAnalysisTaskDotDirfMRI05 <br>
          >> [d,o,behbySess] = slfmriGetDBoverSessions(o,varargin); <br>
          >> [~,VoxelsParams] = slfmriGetVoxTuningParams('vonMisesprior','neuralvector',d,o); <br>
          >> slfmriVisualDatabase(d.instances(d.mySwitch==1,:),'x1',d.myRandomDir(d.mySwitch==1,:),'x2',VoxelsParams.modes1); <br>
          >> slfmriVisualDatabase(d.instances(d.mySwitch==2,:),'x1',d.myRandomDir(d.mySwitch==2,:),'x2',VoxelsParams.modes2) </p>
      </section>

      
      
      
      
      
      
      <h3><a id="Decode-stimulus-features-from-brain-activity" class="anchor" href="#Decode-stimulus-features-from-brain-activity" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Decode stimulus features from brain activity</h3>  
      
      <!--text-->
      <p><strong> Did the subject's brain maintained a representation of the displayed motion direction when the subject switched to his prior ? </strong>
      <p> We decoded the motion direction displayed on each trial from the activity patterns recorded from the subject's brain when he switched to his prior 
      mean and when he switched to the sensory evidence separately.</p> 
      
      <!--code-->
      <section class="code">
      <p> >> slfmriInitClassifAnalysisTaskDotDirfMRI05 <br>
       >> dataClassif = slfmriClassifyDir_x_switch(o) </p>
      </section>
      
      <!--!!!! Figure HERE !!!! -->
      
    
      <!--subsection-->
      <p><strong> The classifier might have a hard time identify difference in patterns elicited by 5 motion directions, can he do better with two motion directions ? </strong> </p>
      <p> We chose the two directions furthest from the prior (225 deg in blue), where switching is the clearest: 15 and 85 degrees (red arrows) </p> 
      
      <!--code-->
      <section class="code">
        <p> >> drawVectors([15 85 155 225 295],[1 1 1 1 1]) </p>
      </section>
      
      <!--figure-->
      <center><img src="images/ClassifyTwoDirections.png" style="width: 100%; height: 100%"/></center>
      
      <p> We classified the two directions from various visually responsive areas of the brain (V1,V2,V3,V3A,hMT,IPS) 
      for subject "s025" over 3 sessions when motion and the prior were weak (6% coherence, 80 deg prior). We also 
      classified the directions from signals recorded outside the brain as a control check that significant accuracies were not 
      spurious (e.g., error in the code).
      
      <!--figure-->
      <center><img src="images/ControlROI.png" style="width: 50%; height: 50%"/></center>
      
      <!--code-->
      <section class="code">
         <p> >> slfmriInitClassifAnalysisTaskDotDirfMRI05_loop; <br> 
              >> [accuracies,ste] = slfmriClassifyTwoDir_x_switch_loop(o); </p>
      </section>
      
      <!--figure-->
      <center><img src="images/ClassifTwoDir.png" style="width: 50%; height: 50%"/></center>
      
      <!--SECTION-->
      <h3><a id="Analysis-of-population-of-voxel-selectivity" class="anchor" href="#Analysis-of-population-of-voxel-selectivity" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Analysis of population of voxel selectivity</h3>  

      <section class="code">
        <p> >> slfMRIwrapperDisVoxSelbalDir </p>
      </section>
      
    </div>
    
    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">projBrainInference maintained by <a href="https://github.com/steevelaquitaine">steevelaquitaine</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

  </body>
</html>
